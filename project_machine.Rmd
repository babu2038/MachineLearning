---
title: "Project_MachineLearning"
output: html_document
---

Loading required library for this project.
```{r}
library(caret)
library(e1071)

```

```{r}
library(rpart)
library(rpart.plot)
library(randomForest)

```
I am going to choose the seed 11111 here.
```{r}
set.seed(11111)

```
# Getting the Data
I already downloaded data to my current directory. So data will be readed from the current directory.
```{r,echo=TRUE}
trainingset <- read.table("pml-training.csv",sep=",",header= T,na.strings=c("NA","#DIV/0!",""))
testingset <- read.table("pml-testing.csv",sep=",",header= T,na.strings=c("NA","#DIV/0!",""))
```
Checking the dimension of our data set
```{r,echo=FALSE}
dim(trainingset)
dim(testingset)

# Delete columns with all missing values
trainingset<-trainingset[,colSums(is.na(trainingset)) == 0]
testingset <-testingset[,colSums(is.na(testingset)) == 0]

# Some variables are irrelevant to our current project: user_name, raw_timestamp_part_1, raw_timestamp_part_,2 cvtd_timestamp, new_window, and  num_window (columns 1 to 7). We can delete these variables.
trainingset   <-trainingset[,-c(1:7)]
testingset <-testingset[,-c(1:7)]

# and have a look at our new datasets:
dim(trainingset)
dim(testingset)

```
# Partioning the training data into two sets
The training data set contains 53 variables and 19622 obs.
The testing data set contains 53 variables and 20 obs.
In order to perform cross-validation, the training data set is partionned into 2 sets: subTraining (75%) and subTest (25%).
This will be performed using random subsampling without replacement.

```{r,results='asis'}
subsamples <- createDataPartition(y=trainingset$classe, p=0.75, list=FALSE)
subTraining <- trainingset[subsamples, ] 
subTesting <- trainingset[-subsamples, ]
dim(subTraining)
dim(subTesting)

```

_Exploratory data analysis_

The variable “classe” contains 5 levels: A, B, C, D and E. A plot of the outcome variable will allow us to see the frequency of each levels in the subTraining data set and compare one another.
```{r,echo=TRUE}
plot(subTraining$classe, col="blue", main="Bar Plot of levels of the variable classe within the subTraining data set", xlab="classe levels", ylab="Frequency")
```

From the graph above, we can see that each level frequency is within the same order of magnitude of each other. Level A is the most frequent with more than 4000 occurrences while level D is the least frequent with about 2500 occurrences.

**  prediction model:Random Forest**

```{r}
model <- randomForest(classe ~. , data=subTraining, method="class")

# Predicting:
prediction <- predict(model, subTesting, type = "class")
# Test results on subTesting data set:
 
confusionMatrix(prediction, subTesting$classe)
```
**Decision**

 The accuracy of the random Forest model is 0.995. The expected out-of-sample error is estimated at 0.005, or 0.5%. The expected out-of-sample error is calculated as 1 - accuracy for predictions made against the cross-validation set. Our Test data set comprises 20 cases. With an accuracy above 99% on our cross-validation data, we can expect that very few, or none, of the test samples will be missclassified.
 
# Submission
 
 
```{r}
# predict outcome levels on the original Testing data set using Random Forest algorithm
predictfinal <- predict(model, testingset, type="class")
predictfinal
```
 
```{r,echo=TRUE}
# Write files for submission
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictfinal)
```
